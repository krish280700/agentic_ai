{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "7e654bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI;\n",
    "from dotenv import load_dotenv;\n",
    "from pypdf import PdfReader;\n",
    "import json;\n",
    "import requests;\n",
    "import gradio as gr;\n",
    "import os;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a453ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True);\n",
    "\n",
    "open_ai_api = os.getenv(\"OPENAI_API_KEY\");\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\");\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\");\n",
    "\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "551f39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push(message):\n",
    "    return requests.post(\n",
    "        \"https://api.pushover.net/1/messages.json\",\n",
    "        data = {\"user\": pushover_user, \"token\": pushover_token, \"message\": message}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2244047d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a23df47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_user_details(email, name, message=\"not provides\"):\n",
    "    try:\n",
    "        push(f\"New user details received: \\nEmail: {email}\\nName: {name}\\nMessage: {message}\");\n",
    "    except Exception as e:\n",
    "        print('API call failed', e)\n",
    "    return {\"recorded\": \"ok\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "13dcaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_unknown_question(question):\n",
    "    try:\n",
    "        push(f\"New unknown question received: \\nQuestion: {question}\");\n",
    "    except Exception as e:\n",
    "        print('API call failed', e)\n",
    "    return {\"recorded\": \"ok\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e4023ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The email address of this user\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's name, if they provided it\"\n",
    "            }\n",
    "            ,\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional information about the conversation that's worth recording to give context\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"question\": {\"type\": \"string\", \"description\": \"The question that couldn't be answered\"}}\n",
    "    },\n",
    "    \"required\": [\"question\"],\n",
    "    \"additionalProperties\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "055ccc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": record_user_details_json},\n",
    "    {\"type\": \"function\", \"function\": record_unknown_question_json}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e1670e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(tool_calls):\n",
    "    results = [];\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name;\n",
    "        args = json.loads(tool_call.function.arguments);\n",
    "        if tool_name == \"record_user_details\":\n",
    "            result = record_user_details(**args)\n",
    "        elif tool_name == \"record_unknown_question\":\n",
    "            result = record_unknown_question(**args)\n",
    "        results.append({\"role\": \"tool\", \"content\": json.dumps(result), \"tool_call_id\": tool_call.id});\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6d64f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_pdf_reader = PdfReader(\"../me/linkedin.pdf\");\n",
    "resume_pdf_reader = PdfReader(\"../me/resume.pdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "173e24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin = \"\"\n",
    "for page in linkedin_pdf_reader.pages:\n",
    "    text = page.extract_text();\n",
    "    if text:\n",
    "        linkedin += text;\n",
    "\n",
    "resume = \"\"\n",
    "for page in resume_pdf_reader.pages:\n",
    "    text = page.extract_text();\n",
    "    if text:\n",
    "        resume += text;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "56a037da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../me/summary.txt\", \"r\") as file:\n",
    "    summary = file.read();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e22ba36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Krishna Sridhar\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8d49be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n ## Resume:\\n{resume}\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b393e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "356412d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"\"\"You are an evaluator for a {name}'s website chatbot agent. \\\n",
    "    You are given a conversation between a user and an agent. \\\n",
    "    Your task is to decide whether the Agent's latest response is acceptable quality and determine if it is in character as {name}. \\\n",
    "    You should look for the following: \\\n",
    "    - The chatbot's response is in character as {name}. \\\n",
    "    - The chatbot's response is professional and engaging. \\\n",
    "    - The chatbot's response is helpful and informative. \\\n",
    "\n",
    "    Here is the information:\n",
    "    Summary: {summary}\n",
    "    LinkedIn Profile: {linkedin}\n",
    "    Resume: {resume}\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "bfdd86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    return f\"\"\"\n",
    "    Here is the conversation:\n",
    "    {history}\n",
    "    Here is the latest message:\n",
    "    {message}\n",
    "    Here is the chatbot's recent message:\n",
    "    {reply}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d48b2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "e96fb31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(message, reply, history) -> Evaluation:\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "939f5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "29216f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}];\n",
    "    done = False;\n",
    "    reply = \"\"\n",
    "    while not done:\n",
    "        client = OpenAI(api_key=open_ai_api);\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools)\n",
    "        \n",
    "        finish_reason = response.choices[0].finish_reason;\n",
    "        reply = response.choices[0].message;\n",
    "        print(reply.content, 'res 1')\n",
    "        if finish_reason == \"tool_calls\":\n",
    "            tool_calls = reply.tool_calls;\n",
    "            results = handle_tool_call(tool_calls);\n",
    "            messages.append(message);\n",
    "            messages.extend(results);\n",
    "        else:\n",
    "            evaluation = evaluator(reply, message, history)\n",
    "            print(evaluation)\n",
    "            if(evaluation.is_acceptable):\n",
    "                done = True\n",
    "            else:\n",
    "                reply = rerun(reply, message, history, evaluation.feedback)\n",
    "                print(reply.content, 'res 2')\n",
    "                done = True\n",
    "            \n",
    "    return reply.content;\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "0ac11d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm glad to hear that you're interested in connecting! Please share your email address, and I’ll make sure to reach out. If you have any specific topics you'd like to discuss, feel free to mention those as well! res 1\n",
      "is_acceptable=True feedback='The chatbot is very helpful and inviting.'\n",
      "None res 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1621, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 553, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 943, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\krish\\AppData\\Local\\Temp\\ipykernel_28232\\3341705395.py\", line 7, in chat\n",
      "    response = client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 1156, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\krish\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[4]': expected an object, but got a string instead.\", 'type': 'invalid_request_error', 'param': 'messages[4]', 'code': 'invalid_type'}}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
